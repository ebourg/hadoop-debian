Source: hadoop
Section: java
Priority: optional
Maintainer: Debian Java Maintainers <pkg-java-maintainers@lists.alioth.debian.org>
Uploaders: Emmanuel Bourg <ebourg@apache.org>
Build-Depends: cdbs,
               cmake,
               debhelper (>= 9),
               default-jdk,
               hardening-wrapper,
               libfuse-dev,
               libjansson-dev,
               pkg-config
Build-Depends-Indep:
               libapache-directory-api-java,
               libapacheds-java,
               libapacheds-kerberos-codec-java,
               libavro-maven-plugin-java,
               libbookkeeper-java,
               libbuild-helper-maven-plugin-java,
               libcommons-cli-java,
               libcommons-codec-java,
               libcommons-collections3-java,
               libcommons-compress-java,
               libcommons-configuration-java,
               libcommons-daemon-java,
               libcommons-io-java,
               libcommons-lang-java (>= 2.6),
               libcommons-logging-java,
               libcommons-math3-java,
               libcommons-net-java (>= 3),
               libcurator-client-java,
               libcurator-framework-java,
               libcurator-recipes-java,
               libgoogle-gson-java,
               libguava-java (>= 18.0-3~),
               libguice-java (>= 3.0),
               libhsqldb-java,
               libhtrace-core-java,
               libhttpclient-java,
               libjackson-json-java,
               libjaxb-api-java,
               libjersey1-client-java,
               libjersey1-guice-java,
               libjersey1-server-java,
               libjersey1-servlet-java,
               libjersey1-json-java,
               libjets3t-java (>= 0.8.1+dfsg-2),
               libjettison-java,
               libjsch-java (>= 0.1.42),
               libjson-simple-java,
               libjsr305-java,
               libleveldb-java,
               liblog4j1.2-java (>= 1.2.17),
               libmaven-antrun-plugin-java,
               libmaven-bundle-plugin-java,
               libmaven-dependency-plugin-java,
               libmaven-exec-plugin-java,
               libmaven-plugin-tools-java (>= 3.3),
               libmaven-war-plugin-java,
               libmaven2-core-java,
               libnetty-3.9-java,
               libprotobuf-java,
               libservlet2.5-java,
               libslf4j-java,
               libxerces2-java,
               libxmlenc-java,
               libzookeeper-java,
               maven-debian-helper (>= 1.5),
               protobuf-compiler
Standards-Version: 3.9.6
Vcs-Git: git://anonscm.debian.org/pkg-java/hadoop.git
Vcs-Browser: https://anonscm.debian.org/cgit/pkg-java/hadoop.git
Homepage: http://hadoop.apache.org

Package: hadoop
Architecture: all
Depends: ${misc:Depends}, libhadoop-tools-java (= ${source:Version})
Description: Apache Hadoop distributed processing framework
 Apache Hadoop is a framework for running applications on large cluster built
 of commodity hardware. It transparently provides applications both reliability
 and data motion. Hadoop implements a computational paradigm named Map/Reduce,
 where the application is divided into many small fragments of work, each of
 which may be executed or re-executed on any node in the cluster. In addition,
 it provides  a distributed file system (HDFS) that stores data on the compute
 nodes, providing very high aggregate bandwidth across the cluster. Both
 MapReduce and the Hadoop Distributed File System are designed so that node
 failures are automatically handled by the framework.

Package: libhadoop-common-java
Architecture: all
Depends: ${maven:Depends}, ${misc:Depends}
Suggests: ${maven:OptionalDepends}
Description: Apache Hadoop distributed processing framework (common)
 Apache Hadoop is a framework for running applications on large cluster built
 of commodity hardware. It transparently provides applications both reliability
 and data motion. Hadoop implements a computational paradigm named Map/Reduce,
 where the application is divided into many small fragments of work, each of
 which may be executed or re-executed on any node in the cluster. In addition,
 it provides  a distributed file system (HDFS) that stores data on the compute
 nodes, providing very high aggregate bandwidth across the cluster. Both
 MapReduce and the Hadoop Distributed File System are designed so that node
 failures are automatically handled by the framework.
 .
 This package contains the common modules.

Package: libhadoop-hdfs-java
Architecture: all
Depends: ${misc:Depends}, libhadoop-common-java (= ${source:Version})
Description: Apache Hadoop distributed processing framework (hdfs)
 Apache Hadoop is a framework for running applications on large cluster built
 of commodity hardware. It transparently provides applications both reliability
 and data motion. Hadoop implements a computational paradigm named Map/Reduce,
 where the application is divided into many small fragments of work, each of
 which may be executed or re-executed on any node in the cluster. In addition,
 it provides  a distributed file system (HDFS) that stores data on the compute
 nodes, providing very high aggregate bandwidth across the cluster. Both
 MapReduce and the Hadoop Distributed File System are designed so that node
 failures are automatically handled by the framework.
 .
 This package contains the hdfs modules.

Package: libhdfs0
Architecture: any
Depends: ${misc:Depends}, ${shlibs:Depends}
Description: Apache Hadoop distributed processing framework (libhdfs)
 Apache Hadoop is a framework for running applications on large cluster built
 of commodity hardware. It transparently provides applications both reliability
 and data motion. Hadoop implements a computational paradigm named Map/Reduce,
 where the application is divided into many small fragments of work, each of
 which may be executed or re-executed on any node in the cluster. In addition,
 it provides  a distributed file system (HDFS) that stores data on the compute
 nodes, providing very high aggregate bandwidth across the cluster. Both
 MapReduce and the Hadoop Distributed File System are designed so that node
 failures are automatically handled by the framework.
 .
 This package contains the native hdfs library.

Package: libhdfs-dev
Section: libdevel
Priority: extra
Architecture: any
Depends: ${misc:Depends}, libhdfs0 (= ${binary:Version})
Description: Apache Hadoop distributed processing framework (libhdfs-dev)
 Apache Hadoop is a framework for running applications on large cluster built
 of commodity hardware. It transparently provides applications both reliability
 and data motion. Hadoop implements a computational paradigm named Map/Reduce,
 where the application is divided into many small fragments of work, each of
 which may be executed or re-executed on any node in the cluster. In addition,
 it provides  a distributed file system (HDFS) that stores data on the compute
 nodes, providing very high aggregate bandwidth across the cluster. Both
 MapReduce and the Hadoop Distributed File System are designed so that node
 failures are automatically handled by the framework.
 .
 This package contains the native hdfs library and its C header.

Package: libhadoop-yarn-java
Architecture: all
Depends: ${misc:Depends}, libhadoop-common-java (= ${source:Version})
Description: Apache Hadoop distributed processing framework (yarn)
 Apache Hadoop is a framework for running applications on large cluster built
 of commodity hardware. It transparently provides applications both reliability
 and data motion. Hadoop implements a computational paradigm named Map/Reduce,
 where the application is divided into many small fragments of work, each of
 which may be executed or re-executed on any node in the cluster. In addition,
 it provides  a distributed file system (HDFS) that stores data on the compute
 nodes, providing very high aggregate bandwidth across the cluster. Both
 MapReduce and the Hadoop Distributed File System are designed so that node
 failures are automatically handled by the framework.
 .
 This package contains the yarn modules.

Package: libhadoop-mapreduce-java
Architecture: all
Depends: ${misc:Depends}, libhadoop-hdfs-java (= ${source:Version}), libhadoop-yarn-java (= ${source:Version})
Description: Apache Hadoop distributed processing framework (mapreduce)
 Apache Hadoop is a framework for running applications on large cluster built
 of commodity hardware. It transparently provides applications both reliability
 and data motion. Hadoop implements a computational paradigm named Map/Reduce,
 where the application is divided into many small fragments of work, each of
 which may be executed or re-executed on any node in the cluster. In addition,
 it provides  a distributed file system (HDFS) that stores data on the compute
 nodes, providing very high aggregate bandwidth across the cluster. Both
 MapReduce and the Hadoop Distributed File System are designed so that node
 failures are automatically handled by the framework.
 .
 This package contains the mapreduce modules.

Package: libhadoop-tools-java
Architecture: all
Depends: ${misc:Depends}, libhadoop-mapreduce-java (= ${source:Version})
Description: Apache Hadoop distributed processing framework (tools)
 Apache Hadoop is a framework for running applications on large cluster built
 of commodity hardware. It transparently provides applications both reliability
 and data motion. Hadoop implements a computational paradigm named Map/Reduce,
 where the application is divided into many small fragments of work, each of
 which may be executed or re-executed on any node in the cluster. In addition,
 it provides  a distributed file system (HDFS) that stores data on the compute
 nodes, providing very high aggregate bandwidth across the cluster. Both
 MapReduce and the Hadoop Distributed File System are designed so that node
 failures are automatically handled by the framework.
 .
 This package contains the tools modules.
